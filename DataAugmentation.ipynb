{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a231b4-fdf3-42b4-ab1f-b4c9542b23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from torchvision.transforms import v2\n",
    "import torchvision\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1999d9-0c49-457e-966c-1197daf2b20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7a9494-37f5-48cf-ad27-26e1a05c0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomAffine(degrees=(0,5), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967bf9e7-a47f-4c0c-b868-3168aca16fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/HDD-1T/KNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d4e09aa-79bd-4e23-9777-b527874b9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_images_per_class = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926c29b9-5a2f-4b06-adc6-8e64488d4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedImageFolderDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.image_folder = torchvision.datasets.ImageFolder(root=root)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_folder[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2e2581-703b-4358-b91d-b16649e1d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TransformedImageFolderDataset(root=root_dir, transform=aug_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2c6ea0-23b5-47b5-ae93-e7c6bab857b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation completed.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over classes and augment images\n",
    "for class_name in dataset.image_folder.classes:\n",
    "    # Create the directory for the class if it doesn't exist\n",
    "    class_dir = os.path.join(root_dir, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    \n",
    "     # Determine how many images are needed for this class\n",
    "    existing_images = [file for file in os.listdir(class_dir) if file.endswith('.jpg')]\n",
    "    images_needed = desired_images_per_class - len(existing_images)\n",
    "    \n",
    "    # Augment existing images to reach the desired number\n",
    "    for i in range(images_needed):\n",
    "        # Randomly select an existing image\n",
    "        image_name = random.choice(existing_images)\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "        \n",
    "        # Load and augment the image\n",
    "        image = Image.open(image_path)\n",
    "        transformed_image = aug_transforms(image)\n",
    "        \n",
    "        # Convert the tensor back to PIL image before saving\n",
    "        transformed_image_pil = transforms.functional.to_pil_image(transformed_image)\n",
    "        \n",
    "        # Save the augmented image\n",
    "        transformed_image_pil.save(os.path.join(class_dir, f'{len(existing_images) + i}.jpg'))\n",
    "\n",
    "        \n",
    "print(\"Augmentation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e34c8-e6d1-4875-b3b8-58744273b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img = Image.open(Path('/HDD-1T/KNN/F_RIGHT/F.30.jpg'))\n",
    "affine_imgs = [aug_transforms(orig_img) for _ in range(4)]\n",
    "img_index = 0\n",
    "for img in affine_imgs:\n",
    "    transformed_image_pil = transforms.functional.to_pil_image(img)\n",
    "    transformed_image_pil.save(os.path.join('/home/antonia/Desktop/TEST KNN', f'{img_index}.jpg'))\n",
    "    img_index+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
